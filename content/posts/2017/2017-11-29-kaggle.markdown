---
Title: 第一次kaggle参赛，铜牌一枚
author: Young
date: 2017-11-29
tags: [kaggle, machine learning]
Status: public
---
[https://www.kaggle.com/yyqing/competitions](https://www.kaggle.com/yyqing/competitions)

巴西的汽车保险公司出的题，根据汽车司机的各种信息，来判断明年出险的概率

我的排名Top 7%, 名次 335/5169

在讨论区向诸位大神学习了种种，受益匪浅

实践中，有两类知识，书本和教材中没有，但是非常有效：

1. 奇淫巧技，例如：特征工程时用到的奇奇怪怪的常量；读入内存较大的数据的处理方案；有的时候OHE效果非常明显；
2. 有的观点和思路只存在于有关最新的普通论文中，没有得大奖的也没有入选什么顶级会议的；或者github上某些几乎没有star的工程，拿来实践试试都会有奇效


p.s.

1. 根据某种特定参数下的CV集得出来的答案很有可能对于题目答案过拟合了，这一次考试中你虽然得了高分，然而对实际生活中应用却不会那么具有普适性。他们就像准备考试不是那么充分却考前蒙对了题目而拿了好名次
2. 之前听人说xgboost秒杀很多kaggle题目，可如今就算你拿着最优化的决策树上场，还是会被强大硬件训练出来的神经网络秒的渣都不剩。比如我是xgboost和lgbm组合上场，单次训练个半个小时出来的结果，就是300多名，而第一名的方案就不一样了，5个模型ensemble，一个xgboost，4个神经网络，他的每一个神经网络的训练时间都是好几个小时还都用到了独立显卡，遇到这种强大的对手只能俯首称臣。