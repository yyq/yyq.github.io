---
Title: deeplearning.ai之卷积神经网络课程总结
author: Young
date: 2017-11-13
tags: [deep learning, cnn, image]
Status: public
---
等了一个月，coursera上的deeplearning.ai的第四门课程终于放出来了，月初忙了几天没空，这两天有空，认认真真刷掉了这门课（看过每一个视频，理解到位每一段视频内容，选择题作业满分，编程作业以及附加作业全部pass）。

在知乎上看过了[https://zhuanlan.zhihu.com/p/21930884](https://zhuanlan.zhihu.com/p/21930884)，中文版的CS231n(by stanford Li FeiFei)的全部notes，受益匪浅，再补一波吴恩达老师的此课，颇有收获。

知识点总结如下：

### 第一周 卷积神经网络

```
Understand the convolution operation
Understand the pooling operation
Remember the vocabulary used in convolutional neural network (padding, stride, filter, ...)
Build a convolutional neural network for image multi-class classification
```

 * 简介计算机视觉
 * 通过简单的矩阵来卷积，进行边缘检测，本科时的数字图像处理课程学过，这个简单
 * padding, 为了卷积时不把边角的像素忽略掉，得按照卷积核的大小在图像周围一圈补充像素，常用的有两种，
  * valid padding也就是no padding，```input: n*n with filter f*f, output: (b-f+1)*(n-f+1)```
  * same padding,也就是输出矩阵和输入矩阵一样大，这样来计算的话```n+2p-f+1=n```,所以```p=(f-1)/2```,啊哈，所以啊，最好一般你的filter都用奇数，搞了偶数那same padding就不好做了哈
 * stride,步长，按照字面意思就好理解了，为了卷积的同时做采样
 
 ```
 input: n*n with filder f*f padding=p
 ouput is : round((n+2p-f)/s+1), round为向下取整
 ```
 
 * 三维矩阵的卷积，当时彩色图像的时候，比如一个图像是```6*6*3```，6乘以6的矩阵是图像大小，3是channel的数量，那么filter不能再是3乘以3了，得用```3*3*3```了，前面两个3是filer的高度和宽度，第三维的3也是channel数，必须和图像的channel一样匹配好才是.

	```
	input: image 6*6*3,   filter 3*3*3
	output: 4*4，   every 3*3*3 filter on 1*1*3(of image), => 1 pixel in 4*4
	
	if we have multiple filters, then the output is 4*4*M
	```

* 每一个过滤器，对应一个偏差b

	```
	Z = W a + b     # a:6*6*3,  W:3*3*3*2,  b:1*2, Z:4*4*2
	a = g(Z)
	```
	
	![](./2017-11-13/cnn-notation.png)
	
* 简单卷积网络举例
 * 卷积层
 * 池化层
 * 全连接层

* pooling layers, 纯粹为了压缩体积
* **why convolutions, 这个重要了，这是思想，为什么要用卷积网络？**
 * **parameter sharing, a feature detector(such as a vertical edge detector)that's useful in one part of the image is probably useful in another part of the image**
 * **Sparsity of connections: In each layer, each output value depends only on a small number of inputs.**
 
### 第一周 编程作业

only with numpy, functions are:

* zero_pad
* conv_single_step, one filter with one slice of input volume
* conv_forward, all filters with whole input volume, also padding and stride
* pool_forward
* conv_backward
* create_mast_from_window( this is backward for max pooling)
* distribute_value(this is backward for average pooling)
 
with TF, code an application to identify SIGNS

* placeholders: in TF, this is for input data/volumes/matrix) 
* init_parameters: shape of W1 W2 Wn, in TF, this is trainable variables
* forward_propagation: conv-forward, pool-forward, FC-flatten
* cost, we use softmax_cross_entropy_with_logits in this case
* whole MODEL, combine those before, sess.run

### 第二周 深度卷积模型，案例学习

```
Understand multiple foundational papers of convolutional neural networks
Analyze the dimensionality reduction of a volume in a very deep network
Understand and Implement a Residual network
Build a deep neural network using Keras
Implement a skip-connection in your network
Clone a repository from github and use transfer learning
```

* 介绍经典网络了，LeNet-5, AlexNet, VGG
* **ResNets**, 大名鼎鼎的残差网络，在激活函数之前直接加上之前的a值，不废话，一图胜千言
![](./2017-11-13/residualblock.png)  ![](./2017-11-13/residualnetwork.png) 

* **why ResNets work**
 * identity function is easy for Residual block to learn
 ![](./2017-11-13/resnet-0.png)  ![](./2017-11-13/resnet-1.png)
 
* **1x1 convolution**, we can use this to shrink the channels
* **Inception Network**, 这个也很屌了：If I don't konw which kind of filter to use, than let's use all, and let the network choose the right, 直接stack，那么就不可避免的出现了很多channel吧，那么1x1就可以用上了，
 ![](./2017-11-13/inception-0.png) ![](./2017-11-13/inception-1.png)
 
### 第二周 编程作业，残差网络

residual netwokrs, transfer learning

with numpy, keras, tensorflow

* 实现identity block
* 实现convolutional block
* 建立ResNet-50模型
* 简单训练一个epoch花了5分钟，太费资源了，作业里意思意思训练一下就好
 
 
### 第三周 目标检测

```
Understand the challenges of Object Localization, Object Detection and Landmark Finding
Understand and implement non-max suppression
Understand and implement intersection over union
Understand how we label a dataset for an object detection application
Remember the vocabulary of object detection (landmark, anchor, bounding box, grid, ...)
```

* 目标定位，localization是指在一张有一辆汽车的图上，把汽车的位置框出来，detection是指首先要发现图上有多少辆车，然后一一框出来，再加上分类，就是在一个图上找多类物体而不仅仅找汽车了
* 地标检测（landmark detection）,标记某些特殊点的坐标，比如汽车方框的中心，左上角，比如人的眼睛，人的鼻子，比如人体躯干
* 滑动窗口检测，呵呵，这个方法直观上容易理解，各种窗口大小，满图像开始找，就是计算量大了点
* 卷积版滑动窗口检测，和卷积神经网络很像，只是最后的FC改成softmax，输出分类预测的概率好了，原图的普通窗口在卷积网络计算之后，只剩一个像素了，整张图一起卷积，计算量就比上一种方法大大下降了
* 方框预测，YOLO算法：先把图片按照3x3或者19x19均分，然后定位车的中心点在哪个矩阵里，然后基于这个矩阵的坐标系（x,y,w,h）横坐标纵坐标都是大于0小于1，长和宽可以大于1
* IoU, Intersection over union, 两个矩形的交集面积减去并集面积，用于重合矩形剔除
* Non-max suppression, 对于一张图上有多个小矩形都检测到了很多辆车，从概率最大的车框开始，应用IoU.
* Anchor Boxes, 先定义好几个anchor box，在此之前，每一个物体分配给物体中心所在的小矩形，之后，每一个物体分配给中心点所在的矩形之后，再陪一个最高IoU的anchor box.
* region proposals, 先观察图片上的区域分区，segmentation algorithm, 然后再开始运算
 * R-CNN,提出区域，一次分类一个区域，输出标签和边界方框
 * Fast R-CNN, 先分区，然后卷积方案，一起来分类
 * Faster R-CNN，用卷积方案来分区

### 第三周 编程练习 自动驾驶之汽车检测

用tensorflow，numpy，pandas，keras

* yolo_filter_boxes, yolo过滤，应用IoU和non-max suppression和阈值来过滤boxes
* 实现iou和non_max_suppression
* 组合一下前面两者
* 载入之前训练好的模型参数，并且用来预测

### 第四周-1 人脸识别

* 人脸确认 face verification
  * 输入人脸，姓名，ID
  * 输出该人脸是否和该姓名ID匹配
* 人脸识别 face recognition
  * 有一个数据库存了K个人的信息
  * 输入一个人脸
  * 输出一个人是否是这K个人中之一或者一个都不是
* one-shot learning，一枪学习？
  * 从一个样例中学习，然后再识别输入图像是否是这个人
  * 学习出一个相似函数，给定的两张图，算出相似度来判断是否同一个人
  * ```d(img1,img2)=degree of difference between images```
* Siamese network，就是用来解决one-shot学习的模型，输入一个人脸，经过几次卷积池化FC之后输出一个一维矩阵f(1),然后第二个图片，输出一个f(2)，两者L2距离比较近的话，就算同一个人了
* Triplet Loss
  * 假设有三张图片，Anchor, positive, negative  APN，训练的过程中，如果随机的选择APN，那么 d(A,P)+alpha<=d(A,N)就会很容易满足，所以我们应该挑选比较“难”一点的图片来进行训练

### 第四周-2 风格转移

* 什么是神经风格转移（neural style transfer）,选择一张图片的内容，选择另外一张图片的风格，然后融合
![](./2017-11-13/style-transfer-eg.png)
* 损失函数，生成图像和原来的两幅图的loss加起来，当然两种loss计算方式是不一样的，如何计算，这是重点
```
J(G) = alpha * J-content(C, G) + beta * J-style(S, G)
```
* J-content 内容损失函数，直接按照两张图卷积过后矩阵的欧氏距离来计算了，
