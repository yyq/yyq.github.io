<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>对数据科学实验的思考 | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="从本周的一位同学的分享开始
他分享的是一系列特征有关的实验，末尾是QA环节，实验质量（实验方式，实验结果的分析）被多个角度质疑，显而易见，他的实验结果大家很难认可了。无论是他个人的时间花费，还是这次分享的质量，都有些苍白。
最近某项目小组，在一个调优目标上，多位同学参与，短时间内也做了大量的实验，从结果来看，无一显著性的提升。其实我的内心也有在怀疑小伙伴们实验做的很仓促（所以很粗糙），写的代码有bug么？上传到评分版的数据有传错么？实验结论难道仅仅只看最终的一个准确率指标比大小？有没有看稍微更详细的一点的实验结果？新加的改动，对重要的预测条目有什么影响？有的实验结果是准确率上升了，按理说应该很高兴，但是我也会问一下有从哪几个角度看一下数据泄露的可能性没？
实验结果最好不要只有最后一个准确率的数字，应该从一个准确率的数字，下钻到更多的细节，有更多的观察，然后给出进一步的分析结论，进而给出进一步想探索的实验思路。
  实验的分析链条上，尽量的严密，逻辑要清晰，连贯，自洽。不要随意猜。
  分析思路枯竭了，再开始猜，可以先有猜想，然后看数字来证明到自己的猜想是对还是错。
  大家在学生阶段的课上应该都学过基本的实验思路，在动手开始实验之前，要明确实验的变量是什么，哪些是不变的，实验过程你会怎么做，预期实验结果是什么。如果结果和预期一致，那么说明了什么，证明了你的什么想法。如果结果和预期不一致，也请回顾实验过程的各个环节（有没有做错哪里？），每个环节的现象是什么，来间接推理为什么结果和预期不一致。想来，做数据科学的实验，也应该保持小时候做科学实验的初心，好奇，探索，严谨，而不是只交出一个数字。
之前和同事A交流的时候，讨论过需要收集很多很多实验结果，来做meta learning，应是有趣的一条路；目前，我的想法有变，单次实验的质量比大量（不一定准确的）实验结果更加重要。
为了尽量去保证团队中各位同学的实验质量，可以有什么手段呢？手把手指导，言传身教？我也没想清楚。
以上的思考，或许是这此听分享给我带来的最大的价值。">
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<meta property="og:title" content="对数据科学实验的思考">
<meta property="og:description" content="从本周的一位同学的分享开始
他分享的是一系列特征有关的实验，末尾是QA环节，实验质量（实验方式，实验结果的分析）被多个角度质疑，显而易见，他的实验结果大家很难认可了。无论是他个人的时间花费，还是这次分享的质量，都有些苍白。
最近某项目小组，在一个调优目标上，多位同学参与，短时间内也做了大量的实验，从结果来看，无一显著性的提升。其实我的内心也有在怀疑小伙伴们实验做的很仓促（所以很粗糙），写的代码有bug么？上传到评分版的数据有传错么？实验结论难道仅仅只看最终的一个准确率指标比大小？有没有看稍微更详细的一点的实验结果？新加的改动，对重要的预测条目有什么影响？有的实验结果是准确率上升了，按理说应该很高兴，但是我也会问一下有从哪几个角度看一下数据泄露的可能性没？
实验结果最好不要只有最后一个准确率的数字，应该从一个准确率的数字，下钻到更多的细节，有更多的观察，然后给出进一步的分析结论，进而给出进一步想探索的实验思路。
  实验的分析链条上，尽量的严密，逻辑要清晰，连贯，自洽。不要随意猜。
  分析思路枯竭了，再开始猜，可以先有猜想，然后看数字来证明到自己的猜想是对还是错。
  大家在学生阶段的课上应该都学过基本的实验思路，在动手开始实验之前，要明确实验的变量是什么，哪些是不变的，实验过程你会怎么做，预期实验结果是什么。如果结果和预期一致，那么说明了什么，证明了你的什么想法。如果结果和预期不一致，也请回顾实验过程的各个环节（有没有做错哪里？），每个环节的现象是什么，来间接推理为什么结果和预期不一致。想来，做数据科学的实验，也应该保持小时候做科学实验的初心，好奇，探索，严谨，而不是只交出一个数字。
之前和同事A交流的时候，讨论过需要收集很多很多实验结果，来做meta learning，应是有趣的一条路；目前，我的想法有变，单次实验的质量比大量（不一定准确的）实验结果更加重要。
为了尽量去保证团队中各位同学的实验质量，可以有什么手段呢？手把手指导，言传身教？我也没想清楚。
以上的思考，或许是这此听分享给我带来的最大的价值。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yyq.github.io/posts/2020/2020-10-22-exp-thinking/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-10-22T00:00:00+00:00">
<meta property="article:modified_time" content="2020-10-22T00:00:00+00:00">
<meta itemprop=name content="对数据科学实验的思考">
<meta itemprop=description content="从本周的一位同学的分享开始
他分享的是一系列特征有关的实验，末尾是QA环节，实验质量（实验方式，实验结果的分析）被多个角度质疑，显而易见，他的实验结果大家很难认可了。无论是他个人的时间花费，还是这次分享的质量，都有些苍白。
最近某项目小组，在一个调优目标上，多位同学参与，短时间内也做了大量的实验，从结果来看，无一显著性的提升。其实我的内心也有在怀疑小伙伴们实验做的很仓促（所以很粗糙），写的代码有bug么？上传到评分版的数据有传错么？实验结论难道仅仅只看最终的一个准确率指标比大小？有没有看稍微更详细的一点的实验结果？新加的改动，对重要的预测条目有什么影响？有的实验结果是准确率上升了，按理说应该很高兴，但是我也会问一下有从哪几个角度看一下数据泄露的可能性没？
实验结果最好不要只有最后一个准确率的数字，应该从一个准确率的数字，下钻到更多的细节，有更多的观察，然后给出进一步的分析结论，进而给出进一步想探索的实验思路。
  实验的分析链条上，尽量的严密，逻辑要清晰，连贯，自洽。不要随意猜。
  分析思路枯竭了，再开始猜，可以先有猜想，然后看数字来证明到自己的猜想是对还是错。
  大家在学生阶段的课上应该都学过基本的实验思路，在动手开始实验之前，要明确实验的变量是什么，哪些是不变的，实验过程你会怎么做，预期实验结果是什么。如果结果和预期一致，那么说明了什么，证明了你的什么想法。如果结果和预期不一致，也请回顾实验过程的各个环节（有没有做错哪里？），每个环节的现象是什么，来间接推理为什么结果和预期不一致。想来，做数据科学的实验，也应该保持小时候做科学实验的初心，好奇，探索，严谨，而不是只交出一个数字。
之前和同事A交流的时候，讨论过需要收集很多很多实验结果，来做meta learning，应是有趣的一条路；目前，我的想法有变，单次实验的质量比大量（不一定准确的）实验结果更加重要。
为了尽量去保证团队中各位同学的实验质量，可以有什么手段呢？手把手指导，言传身教？我也没想清楚。
以上的思考，或许是这此听分享给我带来的最大的价值。"><meta itemprop=datePublished content="2020-10-22T00:00:00+00:00">
<meta itemprop=dateModified content="2020-10-22T00:00:00+00:00">
<meta itemprop=wordCount content="11">
<meta itemprop=keywords content="machine learning,experiment,data,"><meta name=twitter:card content="summary">
<meta name=twitter:title content="对数据科学实验的思考">
<meta name=twitter:description content="从本周的一位同学的分享开始
他分享的是一系列特征有关的实验，末尾是QA环节，实验质量（实验方式，实验结果的分析）被多个角度质疑，显而易见，他的实验结果大家很难认可了。无论是他个人的时间花费，还是这次分享的质量，都有些苍白。
最近某项目小组，在一个调优目标上，多位同学参与，短时间内也做了大量的实验，从结果来看，无一显著性的提升。其实我的内心也有在怀疑小伙伴们实验做的很仓促（所以很粗糙），写的代码有bug么？上传到评分版的数据有传错么？实验结论难道仅仅只看最终的一个准确率指标比大小？有没有看稍微更详细的一点的实验结果？新加的改动，对重要的预测条目有什么影响？有的实验结果是准确率上升了，按理说应该很高兴，但是我也会问一下有从哪几个角度看一下数据泄露的可能性没？
实验结果最好不要只有最后一个准确率的数字，应该从一个准确率的数字，下钻到更多的细节，有更多的观察，然后给出进一步的分析结论，进而给出进一步想探索的实验思路。
  实验的分析链条上，尽量的严密，逻辑要清晰，连贯，自洽。不要随意猜。
  分析思路枯竭了，再开始猜，可以先有猜想，然后看数字来证明到自己的猜想是对还是错。
  大家在学生阶段的课上应该都学过基本的实验思路，在动手开始实验之前，要明确实验的变量是什么，哪些是不变的，实验过程你会怎么做，预期实验结果是什么。如果结果和预期一致，那么说明了什么，证明了你的什么想法。如果结果和预期不一致，也请回顾实验过程的各个环节（有没有做错哪里？），每个环节的现象是什么，来间接推理为什么结果和预期不一致。想来，做数据科学的实验，也应该保持小时候做科学实验的初心，好奇，探索，严谨，而不是只交出一个数字。
之前和同事A交流的时候，讨论过需要收集很多很多实验结果，来做meta learning，应是有趣的一条路；目前，我的想法有变，单次实验的质量比大量（不一定准确的）实验结果更加重要。
为了尽量去保证团队中各位同学的实验质量，可以有什么手段呢？手把手指导，言传身教？我也没想清楚。
以上的思考，或许是这此听分享给我带来的最大的价值。">
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class=bg-black>
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
</div>
</header>
<main class=pb7 role=main>
<article class="flex-l flex-wrap justify-between mw8 center ph3">
<header class="mt4 w-100">
<aside class="instapaper_ignoref b helvetica tracked">
POSTS
</aside>
<div id=sharing class="mt3 ananke-socials">
</div>
<h1 class="f1 athelas mt3 mb1">对数据科学实验的思考</h1>
<p class=tracked>
By <strong>
Young
</strong>
</p>
<time class="f6 mv4 dib tracked" datetime=2020-10-22T00:00:00Z>October 22, 2020</time>
</header>
<div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>从本周的一位同学的分享开始</p>
<p>他分享的是一系列特征有关的实验，末尾是QA环节，实验质量（实验方式，实验结果的分析）被多个角度质疑，显而易见，他的实验结果大家很难认可了。无论是他个人的时间花费，还是这次分享的质量，都有些苍白。</p>
<p>最近某项目小组，在一个调优目标上，多位同学参与，短时间内也做了大量的实验，从结果来看，无一显著性的提升。其实我的内心也有在怀疑小伙伴们实验做的很仓促（所以很粗糙），写的代码有bug么？上传到评分版的数据有传错么？实验结论难道仅仅只看最终的一个准确率指标比大小？有没有看稍微更详细的一点的实验结果？新加的改动，对重要的预测条目有什么影响？有的实验结果是准确率上升了，按理说应该很高兴，但是我也会问一下有从哪几个角度看一下数据泄露的可能性没？</p>
<p>实验结果最好不要只有最后一个准确率的数字，应该从一个准确率的数字，下钻到更多的细节，有更多的观察，然后给出进一步的分析结论，进而给出进一步想探索的实验思路。</p>
<ul>
<li>
<p>实验的分析链条上，尽量的严密，逻辑要清晰，连贯，自洽。不要随意猜。</p>
</li>
<li>
<p>分析思路枯竭了，再开始猜，可以先有猜想，然后看数字来证明到自己的猜想是对还是错。</p>
</li>
</ul>
<p>大家在学生阶段的课上应该都学过基本的实验思路，在动手开始实验之前，要明确实验的变量是什么，哪些是不变的，实验过程你会怎么做，预期实验结果是什么。如果结果和预期一致，那么说明了什么，证明了你的什么想法。如果结果和预期不一致，也请回顾实验过程的各个环节（有没有做错哪里？），每个环节的现象是什么，来间接推理为什么结果和预期不一致。想来，做数据科学的实验，也应该保持小时候做科学实验的初心，好奇，探索，严谨，而不是只交出一个数字。</p>
<p>之前和同事A交流的时候，讨论过需要收集很多很多实验结果，来做meta learning，应是有趣的一条路；目前，我的想法有变，单次实验的质量比大量（不一定准确的）实验结果更加重要。</p>
<p>为了尽量去保证团队中各位同学的实验质量，可以有什么手段呢？手把手指导，言传身教？我也没想清楚。</p>
<p>以上的思考，或许是这此听分享给我带来的最大的价值。</p>
<ul class=pa0>
<li class=list>
<a href=/tags/machine-learning class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">machine learning</a>
</li>
<li class=list>
<a href=/tags/experiment class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">experiment</a>
</li>
<li class=list>
<a href=/tags/data class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">data</a>
</li>
</ul>
<div class="mt6 instapaper_ignoref">
</div>
</div>
<aside class="w-30-l mt6-l">
<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
<p class="f5 b mb3">Related</p>
<ul class="pa0 list">
<li class=mb2>
<a href=/posts/2018/2018-12-07-doodle-recognition/>kaggle | quickdraw-doodle-recognition top 6%</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-09-25-kaggle-model-insights/>kaggle | Machine Learning for Insights Challenge</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-06-29-kaggle-avito/>kaggle | avito-demand-prediction top 10%</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-05-14-kaggle-ensemble-guide/>kaggle模型组合指南</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-05-09-talking-data/>kaggle | talkingdata-adtracking-fraud-detection top 4%</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-01-17-favorita-grocery-sales-forecasting/>kaggle | favorita-grocery-sales-forecasting</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-11-29-kaggle/>第一次kaggle参赛，铜牌一枚</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-10-23-xgboost-tune/>xgboost模型调试攻略</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-10-02-machine-learning-ex-progress/>17年9月份机器学习知识进展</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-12-machine-learning-exercise/>coursera Andrew Ng 机器学习 编程习题总结</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-11-machine-learning-week11/>coursera Andrew Ng 机器学习第十一周笔记 应用举例：photo OCR</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-10-machine-learning-week10/>coursera Andrew Ng 机器学习第十周笔记 大数据量的机器学习</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-09-machine-learning-week9/>coursera Andrew Ng 机器学习第九周笔记 异常检测与推荐系统</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-08-machine-learning-week8/>coursera Andrew Ng 机器学习第八周笔记 降低维度</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-07-machine-learning-week7/>coursera Andrew Ng 机器学习第七周笔记 支持向量机</a>
</li>
</ul>
</div>
</aside>
</article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>