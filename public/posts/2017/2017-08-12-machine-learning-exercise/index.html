<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>coursera Andrew Ng 机器学习 编程习题总结 | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="学习这些知识不是为了学习而学习，是为了解决问题而学习。所以这些知识所配套的编程练习尤为重要了。这门课程做的作业，可算是让我开了眼界，简单的一些代码和并不是特别大量的数据，就能解决一些简单的问题。受益匪浅！记录下来这些，以供之后解决复杂问题的时候给一个参考思路。
这门课程的代码我是用的matlab，我的代码参考链接点击这里
Linear Regression  解决预测房价的问题，已知面积，房间数 写出线性回归的代价函数和梯度下降函数 画图来看，有个直观感受 不同的learning rate有不同的影响，收敛快慢  Logistic Regression   预测某个学生是否通过了某门课程，已知数据包括两次测验的成绩，画出直线决策边界
  预测制造工厂出产的芯片的质量合格与否，根据芯片的两次测试成绩，画出像圆形的决策边界
  sigmoid函数
  代价函数，梯度下降函数
  范化
  Multi-class classification and Neural Network  数字图片的识别，输入图片，输出数字 通过1-vs-N的逻辑回归函数来识别 通过神经网络来识别(这里只实现了前向反馈用来预测)，theta矩阵已知，效果显然比逻辑回归好  Neural Networks Learning  仍然是识别数字 实现了神经网络里的后向反馈，代价函数，梯度下降，随机初始化，泛化，梯度检查等步骤 可视化隐藏层，有个直观感受  Regularized Linear Regression and Bias v.s. Variance  不同的偏差，方差，通过画图观察 画学习曲线，发现了高偏差问题，数据量增多也不管用，那么线性改多项式 多项式回归，画图，调整选择lambda  Support Vector Machines  识别垃圾邮件，亲测自己收到的各种广告垃圾邮件，果然有效！ Informally, the C parameter is a positive value that controls the penalty for misclassified training examples SVM with 高斯内核 决策边界，无比扭曲的曲线都可以适应好 垃圾邮件case:邮件单词预处理，词库预处理，提取邮件特征，训练，预测，GoodJob!">
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<meta property="og:title" content="coursera Andrew Ng 机器学习 编程习题总结">
<meta property="og:description" content="学习这些知识不是为了学习而学习，是为了解决问题而学习。所以这些知识所配套的编程练习尤为重要了。这门课程做的作业，可算是让我开了眼界，简单的一些代码和并不是特别大量的数据，就能解决一些简单的问题。受益匪浅！记录下来这些，以供之后解决复杂问题的时候给一个参考思路。
这门课程的代码我是用的matlab，我的代码参考链接点击这里
Linear Regression  解决预测房价的问题，已知面积，房间数 写出线性回归的代价函数和梯度下降函数 画图来看，有个直观感受 不同的learning rate有不同的影响，收敛快慢  Logistic Regression   预测某个学生是否通过了某门课程，已知数据包括两次测验的成绩，画出直线决策边界
  预测制造工厂出产的芯片的质量合格与否，根据芯片的两次测试成绩，画出像圆形的决策边界
  sigmoid函数
  代价函数，梯度下降函数
  范化
  Multi-class classification and Neural Network  数字图片的识别，输入图片，输出数字 通过1-vs-N的逻辑回归函数来识别 通过神经网络来识别(这里只实现了前向反馈用来预测)，theta矩阵已知，效果显然比逻辑回归好  Neural Networks Learning  仍然是识别数字 实现了神经网络里的后向反馈，代价函数，梯度下降，随机初始化，泛化，梯度检查等步骤 可视化隐藏层，有个直观感受  Regularized Linear Regression and Bias v.s. Variance  不同的偏差，方差，通过画图观察 画学习曲线，发现了高偏差问题，数据量增多也不管用，那么线性改多项式 多项式回归，画图，调整选择lambda  Support Vector Machines  识别垃圾邮件，亲测自己收到的各种广告垃圾邮件，果然有效！ Informally, the C parameter is a positive value that controls the penalty for misclassified training examples SVM with 高斯内核 决策边界，无比扭曲的曲线都可以适应好 垃圾邮件case:邮件单词预处理，词库预处理，提取邮件特征，训练，预测，GoodJob!">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yyq.github.io/posts/2017/2017-08-12-machine-learning-exercise/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2017-08-12T00:00:00+00:00">
<meta property="article:modified_time" content="2017-08-12T00:00:00+00:00">
<meta itemprop=name content="coursera Andrew Ng 机器学习 编程习题总结">
<meta itemprop=description content="学习这些知识不是为了学习而学习，是为了解决问题而学习。所以这些知识所配套的编程练习尤为重要了。这门课程做的作业，可算是让我开了眼界，简单的一些代码和并不是特别大量的数据，就能解决一些简单的问题。受益匪浅！记录下来这些，以供之后解决复杂问题的时候给一个参考思路。
这门课程的代码我是用的matlab，我的代码参考链接点击这里
Linear Regression  解决预测房价的问题，已知面积，房间数 写出线性回归的代价函数和梯度下降函数 画图来看，有个直观感受 不同的learning rate有不同的影响，收敛快慢  Logistic Regression   预测某个学生是否通过了某门课程，已知数据包括两次测验的成绩，画出直线决策边界
  预测制造工厂出产的芯片的质量合格与否，根据芯片的两次测试成绩，画出像圆形的决策边界
  sigmoid函数
  代价函数，梯度下降函数
  范化
  Multi-class classification and Neural Network  数字图片的识别，输入图片，输出数字 通过1-vs-N的逻辑回归函数来识别 通过神经网络来识别(这里只实现了前向反馈用来预测)，theta矩阵已知，效果显然比逻辑回归好  Neural Networks Learning  仍然是识别数字 实现了神经网络里的后向反馈，代价函数，梯度下降，随机初始化，泛化，梯度检查等步骤 可视化隐藏层，有个直观感受  Regularized Linear Regression and Bias v.s. Variance  不同的偏差，方差，通过画图观察 画学习曲线，发现了高偏差问题，数据量增多也不管用，那么线性改多项式 多项式回归，画图，调整选择lambda  Support Vector Machines  识别垃圾邮件，亲测自己收到的各种广告垃圾邮件，果然有效！ Informally, the C parameter is a positive value that controls the penalty for misclassified training examples SVM with 高斯内核 决策边界，无比扭曲的曲线都可以适应好 垃圾邮件case:邮件单词预处理，词库预处理，提取邮件特征，训练，预测，GoodJob!"><meta itemprop=datePublished content="2017-08-12T00:00:00+00:00">
<meta itemprop=dateModified content="2017-08-12T00:00:00+00:00">
<meta itemprop=wordCount content="84">
<meta itemprop=keywords content="ai,machine learning,Andrew Ng,coursera,"><meta name=twitter:card content="summary">
<meta name=twitter:title content="coursera Andrew Ng 机器学习 编程习题总结">
<meta name=twitter:description content="学习这些知识不是为了学习而学习，是为了解决问题而学习。所以这些知识所配套的编程练习尤为重要了。这门课程做的作业，可算是让我开了眼界，简单的一些代码和并不是特别大量的数据，就能解决一些简单的问题。受益匪浅！记录下来这些，以供之后解决复杂问题的时候给一个参考思路。
这门课程的代码我是用的matlab，我的代码参考链接点击这里
Linear Regression  解决预测房价的问题，已知面积，房间数 写出线性回归的代价函数和梯度下降函数 画图来看，有个直观感受 不同的learning rate有不同的影响，收敛快慢  Logistic Regression   预测某个学生是否通过了某门课程，已知数据包括两次测验的成绩，画出直线决策边界
  预测制造工厂出产的芯片的质量合格与否，根据芯片的两次测试成绩，画出像圆形的决策边界
  sigmoid函数
  代价函数，梯度下降函数
  范化
  Multi-class classification and Neural Network  数字图片的识别，输入图片，输出数字 通过1-vs-N的逻辑回归函数来识别 通过神经网络来识别(这里只实现了前向反馈用来预测)，theta矩阵已知，效果显然比逻辑回归好  Neural Networks Learning  仍然是识别数字 实现了神经网络里的后向反馈，代价函数，梯度下降，随机初始化，泛化，梯度检查等步骤 可视化隐藏层，有个直观感受  Regularized Linear Regression and Bias v.s. Variance  不同的偏差，方差，通过画图观察 画学习曲线，发现了高偏差问题，数据量增多也不管用，那么线性改多项式 多项式回归，画图，调整选择lambda  Support Vector Machines  识别垃圾邮件，亲测自己收到的各种广告垃圾邮件，果然有效！ Informally, the C parameter is a positive value that controls the penalty for misclassified training examples SVM with 高斯内核 决策边界，无比扭曲的曲线都可以适应好 垃圾邮件case:邮件单词预处理，词库预处理，提取邮件特征，训练，预测，GoodJob!">
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class=bg-black>
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
</div>
</header>
<main class=pb7 role=main>
<article class="flex-l flex-wrap justify-between mw8 center ph3">
<header class="mt4 w-100">
<aside class="instapaper_ignoref b helvetica tracked">
POSTS
</aside>
<div id=sharing class="mt3 ananke-socials">
</div>
<h1 class="f1 athelas mt3 mb1">coursera Andrew Ng 机器学习 编程习题总结</h1>
<p class=tracked>
By <strong>
Young
</strong>
</p>
<time class="f6 mv4 dib tracked" datetime=2017-08-12T00:00:00Z>August 12, 2017</time>
</header>
<div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>学习这些知识不是为了学习而学习，是为了解决问题而学习。所以这些知识所配套的编程练习尤为重要了。这门课程做的作业，可算是让我开了眼界，简单的一些代码和并不是特别大量的数据，就能解决一些简单的问题。受益匪浅！记录下来这些，以供之后解决复杂问题的时候给一个参考思路。</p>
<p>这门课程的代码我是用的matlab，我的代码参考链接<a href=https://github.com/yyq/coursera-machine-learning>点击这里</a></p>
<h3 id=linear-regression>Linear Regression</h3>
<ul>
<li>解决预测房价的问题，已知面积，房间数</li>
<li>写出线性回归的代价函数和梯度下降函数</li>
<li>画图来看，有个直观感受</li>
<li>不同的learning rate有不同的影响，收敛快慢</li>
</ul>
<h3 id=logistic-regression>Logistic Regression</h3>
<ul>
<li>
<p>预测某个学生是否通过了某门课程，已知数据包括两次测验的成绩，画出直线决策边界</p>
</li>
<li>
<p>预测制造工厂出产的芯片的质量合格与否，根据芯片的两次测试成绩，画出像圆形的决策边界</p>
</li>
<li>
<p>sigmoid函数</p>
</li>
<li>
<p>代价函数，梯度下降函数</p>
</li>
<li>
<p>范化</p>
</li>
</ul>
<h3 id=multi-class-classification-and-neural-network>Multi-class classification and Neural Network</h3>
<ul>
<li>数字图片的识别，输入图片，输出数字</li>
<li>通过1-vs-N的逻辑回归函数来识别</li>
<li>通过神经网络来识别(这里只实现了前向反馈用来预测)，theta矩阵已知，效果显然比逻辑回归好</li>
</ul>
<h3 id=neural-networks-learning>Neural Networks Learning</h3>
<ul>
<li>仍然是识别数字</li>
<li>实现了神经网络里的后向反馈，代价函数，梯度下降，随机初始化，泛化，梯度检查等步骤</li>
<li>可视化隐藏层，有个直观感受</li>
</ul>
<h3 id=regularized-linear-regression-and-bias-vs-variance>Regularized Linear Regression and Bias v.s. Variance</h3>
<ul>
<li>不同的偏差，方差，通过画图观察</li>
<li>画学习曲线，发现了高偏差问题，数据量增多也不管用，那么线性改多项式</li>
<li>多项式回归，画图，调整选择lambda</li>
</ul>
<h3 id=support-vector-machines>Support Vector Machines</h3>
<ul>
<li>识别垃圾邮件，亲测自己收到的各种广告垃圾邮件，果然有效！</li>
<li>Informally, the C parameter is a positive value that controls the penalty for misclassified training examples</li>
<li>SVM with 高斯内核</li>
<li>决策边界，无比扭曲的曲线都可以适应好</li>
<li>垃圾邮件case:邮件单词预处理，词库预处理，提取邮件特征，训练，预测，GoodJob!</li>
</ul>
<h3 id=k-means-clustering-and-princiapl-component-analysis>K-means Clustering and Princiapl Component Analysis</h3>
<ul>
<li>K-means聚类用于压缩图像，通过减少颜色的数量</li>
<li>PCA用于将脸部图片的降维，将32 * 32的图像压缩为10 * 10，体积减少很多（10X），运算加快很多，当需要运用神经网络+人脸识别的时候，用处就大了。</li>
</ul>
<h3 id=anomaly-detection-and-recommender-systems>Anomaly Detection and Recommender Systems</h3>
<ul>
<li>如题</li>
<li>推荐系统还是教程里的电影打分的问题</li>
</ul>
<ul class=pa0>
<li class=list>
<a href=/tags/ai class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">ai</a>
</li>
<li class=list>
<a href=/tags/machine-learning class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">machine learning</a>
</li>
<li class=list>
<a href=/tags/andrew-ng class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Andrew Ng</a>
</li>
<li class=list>
<a href=/tags/coursera class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">coursera</a>
</li>
</ul>
<div class="mt6 instapaper_ignoref">
</div>
</div>
<aside class="w-30-l mt6-l">
<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
<p class="f5 b mb3">Related</p>
<ul class="pa0 list">
<li class=mb2>
<a href=/posts/2017/2017-08-11-machine-learning-week11/>coursera Andrew Ng 机器学习第十一周笔记 应用举例：photo OCR</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-10-machine-learning-week10/>coursera Andrew Ng 机器学习第十周笔记 大数据量的机器学习</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-09-machine-learning-week9/>coursera Andrew Ng 机器学习第九周笔记 异常检测与推荐系统</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-08-machine-learning-week8/>coursera Andrew Ng 机器学习第八周笔记 降低维度</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-07-machine-learning-week7/>coursera Andrew Ng 机器学习第七周笔记 支持向量机</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-06-machine-learning-week6/>coursera Andrew Ng 机器学习第六周笔记 系统设计与优化技巧</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-05-machine-learning-week5/>coursera Andrew Ng 机器学习第五周笔记 神经网络的学习过程</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-04-machine-learning-week4/>coursera Andrew Ng 机器学习第四周笔记 神经网络模型</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-03-machine-learning-week3/>coursera Andrew Ng 机器学习第三周笔记 逻辑回归与泛化</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-02-machine-learning-week2/>coursera Andrew Ng 机器学习第二周笔记 多个变量的线性回归</a>
</li>
<li class=mb2>
<a href=/posts/2017/2017-08-01-machine-learning-week1/>coursera Andrew Ng 机器学习第一周笔记 线性回归</a>
</li>
</ul>
</div>
</aside>
</article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>