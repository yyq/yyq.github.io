<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content>
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<link href=/posts/index.xml rel=alternate type=application/rss+xml title="Young Story">
<link href=/posts/index.xml rel=feed type=application/rss+xml title="Young Story">
<meta property="og:title" content="Posts">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://yyq.github.io/posts/">
<meta itemprop=name content="Posts">
<meta itemprop=description content><meta name=twitter:card content="summary">
<meta name=twitter:title content="Posts">
<meta name=twitter:description content>
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class="pb3-m pb6-l bg-black">
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
<div class="tc-l pv3 ph3 ph4-ns">
<h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
Posts
</h1>
</div>
</div>
</header>
<main class=pb7 role=main>
<article class="pa3 pa4-ns nested-copy-line-height nested-img">
<section class="cf ph3 ph5-l pv3 pv4-l f4 tc-l center measure-wide lh-copy mid-gray"></section>
<section class="flex-ns flex-wrap justify-around mt5">
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-07-machine-learning-week7/ class="link black dim">
coursera Andrew Ng 机器学习第七周笔记 支持向量机
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Support Vector Machines optimization Objective Large Margin Intuition Kernels Using an SVM choice of parameter C
choice of kernel(similarity function)
if Gaussian Kernel, need to choose sigma^2
Not all similarity functions make valid kernels(need to satisfy technical condition called &ldquo;Mercer&rsquo;s Theorem&rdquo; to make sure SVM packages' optimizations run correctly, and do not diverge).
Polynomial kernel: More esoteric: String kernel, chi-square kernel, histogram intersection kernel
multi-class calssification
K SVMs, one to distinguish one from the rest.
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-06-machine-learning-week6/ class="link black dim">
coursera Andrew Ng 机器学习第六周笔记 系统设计与优化技巧
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Advice for Applying Machine Learning 重要的笔记，必须手写上传 Machine Learning System Design email spam example Given a data set of emails, we could construct a vector for each email. Each entry in this vector represents a word. The vector normally contains 10,000 to 50,000 entries gathered by finding the most frequently used words in our data set. If a word is to be found in the email, we would assign its respective entry a 1, else if it is not found, that entry would be a 0.
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-05-machine-learning-week5/ class="link black dim">
coursera Andrew Ng 机器学习第五周笔记 神经网络的学习过程
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Neural Networks: Learning cost function L = total number of layers in the network sl = number of units (not counting bias unit) in layer l K = number of output units/classes the double sum simply adds up the logistic regression costs calculated for each cell in the output layer the triple sum simply adds up the squares of all the individual Θs in the entire network. the i in the triple sum does not refer to training example i Backpropagation Algorithm Backpropagation in Practice thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ] deltaVector = [ D1(:); D2(:); D3(:) ] Theta1 = reshape(thetaVector(1:110),10,11) Theta2 = reshape(thetaVector(111:220),10,11) Theta3 = reshape(thetaVector(221:231),1,11) gradient checking Once you have verified once that your backpropagation algorithm is correct, you don&rsquo;t need to compute gradApprox again.
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-04-machine-learning-week4/ class="link black dim">
coursera Andrew Ng 机器学习第四周笔记 神经网络模型
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Neural Networks:Representation 这个周的课程很简单，就是介绍了神经网络是什么样子的
introduction examples multi classification example
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-03-machine-learning-week3/ class="link black dim">
coursera Andrew Ng 机器学习第三周笔记 逻辑回归与泛化
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Logistic Regression Classification The classification problem is just like the regression problem, except that the values y we now want to predict take on only a small number of discrete values. For now, we will focus on the binary classification problem in which y can take on only two values, 0 and 1.
Logistic Regression Model Decision Boundary The decision boundary is the line that separates the area where y = 0 and where y = 1.
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-02-machine-learning-week2/ class="link black dim">
coursera Andrew Ng 机器学习第二周笔记 多个变量的线性回归
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Linear Regression with Multiple Variables Multiple Features Gradient Descent for Multiple Variables Feature Scaling We can speed up gradient descent by having each of our input values in roughly the same range.
feature scaling: involves dividing the input values by the range of the input variable resulting in a new range of just 1. mean normalization: involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero.
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-01-machine-learning-week1/ class="link black dim">
coursera Andrew Ng 机器学习第一周笔记 线性回归
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
machine learning supervised learning, unsupervised learning, others(reinforcement learning, recommender system)
supervised learning regressing，predict input into continuous result classification, predict input into distract result examples：
given size, rooms, predict house price, like 1M, 100Grand, 1B house prize is expensive or cheap ? given picture with human, predict his age: 0.1，12.5，78.8 given a patient with tumor, predict it&rsquo;s a malignant or benign unsupervised learning problems with little or no idea what our results should look like
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-05-06-hadoop-mapreduce/ class="link black dim">
学习hadoop和mapreduce
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
前言 4月底离职了，最近赋闲在家，趁着有空拓宽一下视野，学学大数据有关的基础知识吧。扫了一圈公开课的网站，Udacity网站有了专门的中文网站,不过教学视频还是英文的， 找了Hadoop和MapReduce入门这个课程，链接https://cn.udacity.com/course/intro-to-hadoop-and-mapreduce&ndash;ud617，略有收获。
Hadoop生态系统 大数据简介 首先对大数据得有一个概念，我理所当然认为，数据量很大，比如有1TB的数据，那么就是大数据。稍加修饰一下，一台单独的电脑无法轻松处理的数据，则是big data。再看看别人的理解：
大数据概念中重要的的3个V, Volume, Variety, Velocity.
Volume,特指数据量的大小，比如说1TB,1PB Variety,指数据的类型格式什么的，数据会从很多个不同的来源过来，有很多不同的格式样子 Velocity,生成数据的速度,处理数据的速度, 数据的生产者和消费者都得速度快啊。 Hadoop来源 某工程师有一个还不会太会说话的儿子，他儿子给自己的玩具取了个名字，发音为Hadoop.
Hadoop工程的核心是两个部分，一个是存储数据，HDFS(Hadoop Distributed File System),另外一个部分是处理数据，MapReduce。
Hadoop生态系统 底层是HDFS来存储数据的，基于此，有一个默认的MR来处理数据。 其他的开源软件，有的是把数据导入进Hadoop集群的，有的是让Hadoop更加容易使用的。例如Hive和Pig等。
Hive,不用写麻烦的mapper和reducer的代码，写的和标准SQL比较像就行了。
Pig也是一种更容易的脚本
Impala，也是可以使用类似标准SQL的语法，直接访问HDFS里的数据，而不需要经过MapReduce。
sqoop，把传统数据库的内容导入到HDFS。Flume也类似。
HBase,实时数据库，基于HDFS的。
看图学习Hadoop并解决问题 HDFS图解 一个体积较大的文件会被分块存储，例如按照64MB来分割，150MB的就会被分成3块
集群中有一个namenode节点，会将这三块数据分别存储在不同的数据节点上
然后每一块数据都会复制两份到其他的数据节点上
namenode是个非常重要的节点了，一个namenode如果挂了，整个集群就废了。那么一般用什么方法来保障namenode的高可用呢，一个方法是备份，在集群里放入第二个namenode，备用。另外一个方法是，把namenode里的数据通过NFS的方式，存储在另外的存储机器里，namenode节点机器可以坏掉，不过数据没有丢失，可以拿来恢复。
MapReduce图解 我们通过下面这个具体的问题来学习MR. 我们有一个连锁店的销售数据，数据形式应该是很多本账单。然后我们想统计每个单独的店铺销售总量。
每一条销售数据的格式大概就是，日期，销售店铺（即城市名称），销售类别，销售价格
按照MapReduce的思路来做这个事情，先找来三个人作为Mappers，分给他们一些账本，然后他们分别将自己账本里的数据，按照店铺分个类，一类一类分好，然后再找来reducers，他们每个人负责某些特定的店铺，收集Mapper手里的某店铺的所有数据，收集完毕之后，统计，给出结果。
上面的事例还有几个重要的点没有说明，1. 中间结果都用哈希表的方式来存储，比如某一条销售记录可以存储为，key是销售店铺名称，value是销售额 2. map之后，会有一个shuffle and sort的过程，会将数据按照key的字母顺序排序 3. Hadoop中默认设置reducer的数量是1.
MapReduce设计模式 用图说话
有三种情况，是比较合适使用MR的。
过滤模式 简单过滤 布隆过滤，不懂的请自行谷歌。我记得这是搜索引擎中用到的技术，大量数据的查重，效率很高 采样 随机采样 求值Top N 概括模式 反向索引，也是搜索引擎中用到的技术，根据关键字来检索网页/文章/帖子 数值概括 计数 最小、最大 第一，最后 中位数，平均值，标准差 结构模式 当你要把数据从RDBMS移植到Hadoop后，这种模式就有用了。在对数据集进行分析的时候，MapReduce的过程中，中间数据的格式和内容都可以自己重新定义，就可以免去你的RDBMS中对各个数据集的live join操作，这可是能省下不少时间。
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-03-31-burpsuite-ios10-app/ class="link black dim">
Burpsuite实践：iOS app刷点击量
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
需求 最近有个做媒体的朋友，她们发表在某app上的文章，有点击量的KPI，问我能不能帮刷一刷阅读量。最近学了burpsuite，正好练习练习。
分析 稍微一观察，那app还比较简陋，同一个手机里，反复的去点击文章，再退出，就会增加点击量。
那目标就比较简单了，观察在手机上点击阅读某篇文章的时候，会有什么样的网络请求，再重复就行了。之前想象的不断切换IP的难度也就没有了。
实践 打开Burpsuite监听 首先在BurpSuite里找到Proxy,把Intercept关掉，这里不需要拦截请求。在option里添加一个新的Listeners，端口号填好，Bind to address选择All interfaces.其他默认。
设置手机wifi 打开手机WIFI的设置，代理选手动，填上自己电脑的IP地址和刚刚设定的端口号。
安装CA证书 对于https的请求，这里是最重要的一步，否则你的app里只会显示各种没有网络无法连接等错误
打开http://burp,按照网页右上角的提示安装CA Certificate
这还没完！！更重要的一个步骤：如果你的iOS系统是比较新的，比如我手机是iOS10.3，那么你还要到手机的设置=>通用=>关于本机=>证书信任设置里，打开对PortSwigger CA证书的完全信任
这个步骤花了我足足两个小时有没有，找便了互联网都没有看到有人说要设置手机打开证书完全信任，然后认认真真看官网页面介绍如何安装CA证书，support.portswigger.net。终于，在这个页面正文的后面，很不起眼的一个小提示里说到了这个point，finally my app works fine! WTF! 那里还说了他的这个介绍文档是基于iOS8.1.2的iPad mini.其他版本的iOS可能需要这个操作。
目测是apple为了提升iOS的安全性，就算被意外安装了证书，也不会默认完全信任。要用app通过代理顺利的请求https的内容的话，需要设置手机完全信任这个代理的CA Certificate才行。
重放网络请求 这个简单了，手机app里随意点一点，可以发现每次点击一个新的文章，都会有一个post请求和一个get请求。先拿post请求实验，用send to Intruder, 然后clean掉所有潜在的payload positions,在payloads选项里，选择null payloads,然后设置一下循环次数，先来个5000吧。
我滴乖乖呀，一分钟左右吧，该文章阅读量明显的从2.8万上涨到18.4万。可是我明明只有5000次请求。问了问朋友，这大概是他们统计数据的时候有作假。但是，anyway，我这5000次请求可是货真价实的给该文章增加了不少阅读量。
lessons learned 实战和看视频学习使用软件是两回事儿，有的细节上的设置和设计，差一点点就是功亏一篑谬以千里 有不懂的知识，google里前5个链接没找到答案的话，那么认真阅读官方文档，哪怕细小的一个提示框都不可以错过
</div>
</div>
</div>
</div>
<div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-03-29-sql-injection-attacks-defense-3/ class="link black dim">
《SQL注入攻击与防御》之防御
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
代码层防御 领域驱动的安全性 SQL注入之所以发生，是因为我们的应用程序不正确的将数据在不同表示方式之间进行映射 通过将数据封装到有效的值对象中，并限制对原始数据的访问，我们就可以控制对数据的使用 使用过参数化语句 动态SQL（或者将SQL查询组装成包含受用户控制的输入的字符串并提交给数据库）是引发SQL注入漏洞的主要原因 应该使用参数化语句（也叫做预处理语句）而非动态SQL来安全的组装SQL查询 在提供数据时可以只使用参数化语句，但却无法使用参数化语句来提供SQL关键字或标识符（比如表名或者列名） 验证输入 尽可能坚持使用白名单输入验证（只接收期望的已知良好的输入） 确保验证应用受到的所有受用户控制的输入的类型，大小，范围和内容 只有当无法使用白名单输入验证时才能使用黑名单输入验证（拒绝已知不良的或基于签名的输入） 绝不能单独只使用黑名单检验数据。至少应该总是将它与输出编码技术一起结合使用 编码输出 确保对包含用户可控制输入的查询进行正确编码以防止使用单引号或其他字符来修改查询 如果正在使用LIKE子句，请确保对LIKE中的通配符恰当的编码 在使用从数据库接收到的数据之前确保已经对数据中的敏感内容进行了恰当的输入验证和输出编码 规范化 将输入编码或变味规范格式后才能执行输入验证过滤器和输出编码 请注意，任何单个字符都存在多种表示方式以及编码方法 尽可能使用白名单输入验证并拒绝非规范格式的输入 通过设计来避免SQL注入的危险 使用存储过程以便在数据库层拥有较细粒度的许可 可以使用数据访问抽象层来对整个应用施加安全的数据访问 设计时，请考虑对敏感信息进行附加的控制 平台层防御 使用运行时保护 无法修改代码时，运行时保护是应对SQL注入的一种有效技术 如果调整得当，Web应用防火墙可以有效监测，缓和和预防SQL注入 运行时保护可以跨越多层，多级，其中包括网络，web服务器，应用程序框架以及数据库服务器 确保数据库安全 加固数据库虽然无法完全阻止SQL注入，但却可以显著降低其影响 应该只将攻击者沙箱化在应用程序所用数据上。在锁定的数据库服务器中，不应该影响所连接网络上的其他数据库和系统 应该将访问局限在必须的数据库对象上，比如存储过程只授予EXECUTE许可，此外，对敏感数据明智的使用强加密技术可以防止未经验证的数据访问 额外的部署考虑 加固过的web层部署和网络架构无法完全阻止SLQ注入，但却可以显著降低其影响。 面对自动攻击者的威胁（比如SQL注入蠕虫），尽量减少网络，web和应用程序级别上的泄露，将有助于减少被发现的机会 架构得当的网络应该只允许使用验证过的连接来连接数据库服务器，并且数据库服务器自身不应该产生带外连接 确认并从SQL注入攻击中恢复 调查可疑的SQL注入攻击 只能由计算机安全事件响应人员和组织中已授权执行调查的取证专家，来执行SQL注入攻击的调查取证工作。 合理的调差取证实践要求 在调查取证期间，应该对收集到的所有文件做到真正bit-for-bit复制 应该为复制的每一个文件生成哈希值，并与源文件的哈希值进行比较，以验证bit-for-bit复制的完整性 将调查取证期间执行的所有操作记录在文档中，包括对RDBMS执行的所有查询和返回的查询结果 确保所有收集到的文件写入洁净的存储介质中，并保存在一个安全的地方 分析数字化痕迹 数字化痕迹就是相关数据的集合 对于SQL注入攻击的调查取证，下列痕迹非常有用：web服务器的日志文件，数据库执行计划，事务日志和数据库对象的时间戳 识别SQL注入攻击活动 对web服务器的日志文件执行一次广泛的分析，查找异常偏高的web请求数量出现的日期，或者web服务器与客户端计算机之前带宽利用率异常偏高的日期 检查数据库执行计划和相关日志，查找恶意查询 检查食物日志，寻找在攻击时间段内出现的可疑活动，重点关注已执行的INSERT,UPDATE和DELETE语句 检查数据库对象的时间戳，以识别用户账号的创建，权限提升和表的创建操作 确认SQL注入攻击是否成功 如果发现下列情况，就可以确认一次SQL注入攻击已经成功 在数据库的执行计划或相关数据库日志中捕获了SQL注入的活动 在未经授权的情况下，创建或修改了事物或对象 遏制安全事件 拔除受损害数据库和相应web服务器的网线 评估涉及的数据 必须对数据进行评估，以确保组织机构确定适当的监管和法律要求 通知正确的人员 应该由受损害组织机构的高级管理人员和法律顾问对损害通报进行管控 确定攻击者在系统上执行的操作 可以通过对数据库进行取证，确定攻击者在攻击期间执行的具体操作 确定攻击的有效载荷 备份受害的数据库 提取恶意的SQL注入查询 检查并理解恶意查询的逻辑，从而理解攻击载荷企图实现什么目的 搜索对恶意查询的引用 确定已识别的恶意查询是否属于静态或动态攻击载荷的一部分 查找多种漏洞 应该根据承载的是静态载荷还是动态载荷对攻击进行分类 根据攻击载荷确定如何从安全事件中恢复 从SQL注入攻击中恢复 将数据库恢复到已知的良好状态 检验数据库服务器的配置 识别并修复SQL注入漏洞 在线恢复系统并恢复web服务
</div>
</div>
</div>
</div>
</section>
<ul class="pagination pagination-default">
<li class=page-item>
<a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a>
</li>
<li class=page-item>
<a href=/posts/page/2/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a>
</li>
<li class=page-item>
<a href=/posts/ aria-label="Page 1" class=page-link role=button>1</a>
</li>
<li class=page-item>
<a href=/posts/page/2/ aria-label="Page 2" class=page-link role=button>2</a>
</li>
<li class="page-item active">
<a aria-current=page aria-label="Page 3" class=page-link role=button>3</a>
</li>
<li class=page-item>
<a href=/posts/page/4/ aria-label="Page 4" class=page-link role=button>4</a>
</li>
<li class=page-item>
<a href=/posts/page/5/ aria-label="Page 5" class=page-link role=button>5</a>
</li>
<li class=page-item>
<a href=/posts/page/4/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a>
</li>
<li class=page-item>
<a href=/posts/page/11/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a>
</li>
</ul></article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>