<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>记近两天调优图像训练的过程 | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="起因  拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。  what i&rsquo;ve done  认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧：  tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b   找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。  &#34;&#34;&#34;stream data by batch&#34;&#34;&#34; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &#34;&#34;&#34; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &#34;&#34;&#34; self.">
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<meta property="og:title" content="记近两天调优图像训练的过程">
<meta property="og:description" content="起因  拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。  what i&rsquo;ve done  认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧：  tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b   找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。  &#34;&#34;&#34;stream data by batch&#34;&#34;&#34; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &#34;&#34;&#34; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &#34;&#34;&#34; self.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yyq.github.io/posts/2018/2018-03-30-opt-image-training/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2018-03-30T00:00:00+00:00">
<meta property="article:modified_time" content="2018-03-30T00:00:00+00:00">
<meta itemprop=name content="记近两天调优图像训练的过程">
<meta itemprop=description content="起因  拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。  what i&rsquo;ve done  认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧：  tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b   找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。  &#34;&#34;&#34;stream data by batch&#34;&#34;&#34; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &#34;&#34;&#34; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &#34;&#34;&#34; self."><meta itemprop=datePublished content="2018-03-30T00:00:00+00:00">
<meta itemprop=dateModified content="2018-03-30T00:00:00+00:00">
<meta itemprop=wordCount content="267">
<meta itemprop=keywords content="image,deep learning,resnet,"><meta name=twitter:card content="summary">
<meta name=twitter:title content="记近两天调优图像训练的过程">
<meta name=twitter:description content="起因  拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。  what i&rsquo;ve done  认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧：  tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b   找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。  &#34;&#34;&#34;stream data by batch&#34;&#34;&#34; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &#34;&#34;&#34; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &#34;&#34;&#34; self.">
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class=bg-black>
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
</div>
</header>
<main class=pb7 role=main>
<article class="flex-l flex-wrap justify-between mw8 center ph3">
<header class="mt4 w-100">
<aside class="instapaper_ignoref b helvetica tracked">
POSTS
</aside>
<div id=sharing class="mt3 ananke-socials">
</div>
<h1 class="f1 athelas mt3 mb1">记近两天调优图像训练的过程</h1>
<p class=tracked>
By <strong>
Young
</strong>
</p>
<time class="f6 mv4 dib tracked" datetime=2018-03-30T00:00:00Z>March 30, 2018</time>
</header>
<div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h2 id=起因>起因</h2>
<ul>
<li>拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。</li>
</ul>
<h2 id=what-ive-done>what i&rsquo;ve done</h2>
<ul>
<li>认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。</li>
<li>后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。</li>
<li>将来用的时候可以参考的这几个链接，描述tf读取数据的技巧：
<ul>
<li><a href=https://www.tensorflow.org/extend/new_data_formats>tensorflow 官网链接1</a></li>
<li><a href=https://www.tensorflow.org/programmers_guide/datasets>tensorflow 官网链接2</a></li>
<li><a href=https://blog.csdn.net/u012759136/article/details/52232266>博客 a</a></li>
<li><a href=https://blog.csdn.net/freedom098/article/details/56013625>博客 b</a></li>
</ul>
</li>
<li>找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了<a href=https://keras.io/models/sequential/#sequential-model-methods>官网文档</a>，然后也找到了一位斯坦福同学的<a href=https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html>博客</a>，我就按着这两个做下来，恩，完成了，效果不错。</li>
</ul>
<pre tabindex=0><code>&quot;&quot;&quot;stream data by batch&quot;&quot;&quot;
import numpy as np
import keras
from keras.utils import np_utils
from PIL import Image

class DataGenerator(keras.utils.Sequence):

    def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True):
        &quot;&quot;&quot;
        :param data: 包括了图片名称，路径，四个标签
        :param batch_size: 一批训练128张图片
        :param dim: 图片的维度
        :param n_classes: 有多少种汉字
        :param shuffle: 每个epoch末尾，是否打乱index顺序
        &quot;&quot;&quot;
        self.name_list, self.fullpath_list, self.y0, self.y1, self.y2, self.y3 = data
        self.indexes = np.arange(len(self.name_list))
        self.dim = dim
        self.batch_size = batch_size
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()

    def on_epoch_end(self):
        &quot;&quot;&quot;
        Updates indexes after each epoch
        :return:
        &quot;&quot;&quot;
        if self.shuffle is True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, indexes_temp):
        &quot;&quot;&quot;
        Generates data containing batch_size samples
        :param indexes_temp:
        :return:
        &quot;&quot;&quot;
        x = []
        y = [[] for i in range(4)]

        for index in indexes_temp:
            img = Image.open(self.fullpath_list[index])
            corp_img = img.crop((186, 0, 300, 30))
            corp_img = corp_img.resize((128, 32))
            image = np.array(corp_img)
            image = image[..., :3]
            x.append(image)

            y[0].append(self.y0[index])
            y[1].append(self.y1[index])
            y[2].append(self.y2[index])
            y[3].append(self.y3[index])

        x = np.asarray(x, dtype=np.float32)
        x = x / 255.0
        y = [np.asarray(y[i], dtype=int) for i in range(4)]
        y = [np_utils.to_categorical(y[i], self.n_classes) for i in range(4)]

        return x, [y[0], y[1], y[2], y[3]]

    def __len__(self):
        &quot;&quot;&quot;
        Denote the number of batches per epoch
        :return:
        &quot;&quot;&quot;
        return int(np.floor(len(self.name_list) / self.batch_size))

    def __getitem__(self, index_batch):
        &quot;&quot;&quot;
        Generate on batch of data
        :param index_batch: the index of batch
        :return:
        &quot;&quot;&quot;
        indexes_temp = self.indexes[index_batch * self.batch_size: (index_batch + 1) * self.batch_size]
        x, [y0, y1, y2, y3] = self.__data_generation(indexes_temp)
        return x, [y0, y1, y2, y3]
</code></pre><ul>
<li>ps小坑一个: 在validator用fit_generator的时候，tensorboard没法正常工作了，在github上看到<a href=https://github.com/keras-team/keras/issues/3358>https://github.com/keras-team/keras/issues/3358</a>这还是一个open的issue，在博客下留言请教了，博客作者回复他也没有很好的解决方案。</li>
</ul>
<h2 id=whats-more>what&rsquo;s more</h2>
<ul>
<li>数据可以分批次装下之后，可以正常运行了，不过又发现处理起来特别慢，显卡经常是一会儿100%然后就休息很长一段时间了，又仔细开始找原因，发现是IO效率低下了，说人话就是：大概是花了100秒钟读取图片到内存，然后CPU花了20秒钟裁切图片，然后送到GPU，GPU全力工作两秒钟就干完活了就在休息。</li>
<li>improvement 1: <code>iostat -y 1</code>, 命令里看到io速度很慢，把数据全部挪到SSD硬盘上，<code>tps</code>和<code>KB_read/s</code>都是原来的10倍了你敢信，可能那台电脑上有不少人都在用机械硬盘工作导致那个盘速度太慢。</li>
<li>improvement 2：读取图片和切图的python的库，从<code>cv2</code>换成了<code>pillow-simd</code>, 从这里的<a href=http://python-pillow.org/pillow-perf/>benchmarks分析</a>说后者在很多情况下比前者牛逼太多，换完后确实发现有提升。</li>
</ul>
<h2 id=result>result</h2>
<p>看到 tps和KB_read/s的数据 很稳定了，持续的读进来图片, CPU使用率也很稳定，保持在17左右。然后间接带来的效果，GPU的利用率也就比原来高了不少，不会经常在休息了。</p>
<p>优化之后，在公司的电脑上训练内存消耗为之前的二十分之一，200GB->10GB，在我的显卡运算能力和显存都相对较小的情况下，我的模型训练时间没有增加，模型训练效果与之前相同。</p>
<h2 id=future-improvement>future improvement</h2>
<p>很明显可以多线程多个cpu同时开搞么，现阶段的改进已经足够这些天的实验了，就先不费功夫写多进程代码了。</p>
<ul class=pa0>
<li class=list>
<a href=/tags/image class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">image</a>
</li>
<li class=list>
<a href=/tags/deep-learning class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">deep learning</a>
</li>
<li class=list>
<a href=/tags/resnet class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">resnet</a>
</li>
</ul>
<div class="mt6 instapaper_ignoref">
</div>
</div>
<aside class="w-30-l mt6-l">
<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
<p class="f5 b mb3">Related</p>
<ul class="pa0 list">
<li class=mb2>
<a href=/posts/2017/2017-11-13-cnn/>deeplearning.ai之卷积神经网络课程总结</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-02-24-sp-society-camera-model-identification/>kaggle | sp-society-camera-model-identification 看图认相机</a>
</li>
<li class=mb2>
<a href=/posts/2018/2018-01-25-statoil-iceberg-classifier-challenge/>kaggle | statoil-iceberg-classifier-challenge 捡到铜牌一个</a>
</li>
</ul>
</div>
</aside>
</article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>