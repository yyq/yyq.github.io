<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>deep learning on Young Story</title><link>https://yyq.github.io/tags/deep-learning/</link><description>Recent content in deep learning on Young Story</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 30 Mar 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://yyq.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>记近两天调优图像训练的过程</title><link>https://yyq.github.io/posts/2018/2018-03-30-opt-image-training/</link><pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2018/2018-03-30-opt-image-training/</guid><description>起因 拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。 what i&amp;rsquo;ve done 认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧： tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b 找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。 &amp;quot;&amp;quot;&amp;quot;stream data by batch&amp;quot;&amp;quot;&amp;quot; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &amp;quot;&amp;quot;&amp;quot; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &amp;quot;&amp;quot;&amp;quot; self.</description></item><item><title>kaggle | sp-society-camera-model-identification 看图认相机</title><link>https://yyq.github.io/posts/2018/2018-02-24-sp-society-camera-model-identification/</link><pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2018/2018-02-24-sp-society-camera-model-identification/</guid><description>此题目标为根据照片来判断牌照相机的型号
这件事情的原理是：每一家设备都有自己的数字图像处理算法，总会有属于自己的图像特征
这件事情的意义在于：警察破案，图片是否有被软件修改等等
我的kaggle账号:https://www.kaggle.com/yyqing/competitions
0 自评 自己做的第二个图像类的题目，最大的收获就是体验到了extra data的威力，在论坛区看到有大家讨论说使用额外的一些的数据，50GB的训练集果然效果不错，直接把我的public LB成绩从0.87提升到0.92，后来经过自己的各种transfer learn和fine tune keras里的一些模型，然后组合，在private LB拿到了0.96的分数。看看排名前几的大神的总结里，很多人都使用了比我找的数据集更大的数据集，所以准确率也比我高出几个数量级（第一名0.9896）。
训练大量图像是一件非常非常消耗时间的事情，优化的方向有这么几个：1)切取大图像中的小块来训练;2)显卡计算能力利用率提高，注意显卡的频率，内存，注意程序中的CPU处理部分，做到及时处理一直给显卡喂数据，别让显卡时忙时闲 3)算法的优化，能并行做计算的部分尽量，不过注意估算好显卡的内存消耗，过大过小都是一种浪费 4)transfer来的不同的模型，参数数量不一样，最小图片像素也不一样 5) 做好pipeline
1 高分答案集锦 第一名 Pavel Pleskov 模型 参考了Andres的代码，用pyTorch实现了，如下模型有较好的效果
984_densenet201_antorsaegen_29_0.98624 976_densenet201_antorsaegen_62_0.98271 977_resnet50_antorsaegen_119_val_0.9815 976_DenseNet201_do0.3_doc0.0_avg-epoch072-val_acc0.981250 967_InceptionResNetV2_do0.1_avg-epoch154-val_acc0.965625 962_Xception_do0.3_avg-epoch079-val_acc0.991667 (leaky validation, pls ignore) 所有模型的输入图像都用的512*512，并且都是Test Time Augmentation(测试时也用增强过的数据)。这里是最大败笔，因为后来发现及时用较小size的图片可以更快的训练，然后更多的TTA可以达到相似的准确率
数据 我服，他另外下载了300GB从flickr和yandex.foto的图片。过滤掉分别率不适合的图片，质量不好的图片（图片质量可以用ImageMagick得到），自己用selenium做爬虫抓来的图片。
硬件 五个队员，有五个1080ti和一个1070
提交 平均所有的TTA所有的模型，by power mean powers of 1 2 4.最后有较大的LB overfit, public LB 0.991 private LB 0.985 通过hold-out，融合预测结果。20个xgboost，20个lightGBM，12个Keras，public LB 0.986, private LB 0.989. 关键点 收集尽可能多的图像数据，做好清理 尝试更小的图片切图，尝试所有的架构类型 LB probing是恶魔，相信自己的CV.</description></item><item><title>kaggle | statoil-iceberg-classifier-challenge 捡到铜牌一个</title><link>https://yyq.github.io/posts/2018/2018-01-25-statoil-iceberg-classifier-challenge/</link><pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2018/2018-01-25-statoil-iceberg-classifier-challenge/</guid><description>此题目标为识别图像中是否有冰山，数据图像均为卫星拍摄海面获得
我的kaggle账号:https://www.kaggle.com/yyqing/competitions
0 自评 第一次开始尝试图像的题目，和普通回归类的题目还真是不一样，除了修改一些别人的模型看得懂别人模型之外，自己还没有水平直接改进到10%。coursera的课程知识不够用了，觉得自己有知识瓶颈了，计划把cs231n刷一遍（中文字幕的，编程作业一定自己完成的），目标要至少做到：在不做实验的情况下，增删改查模型的各个地方，对自己的运行结果，得利用先验理论知识进行预判。这样的话，可以在实践各种方案的同时，持续强化自己对理论知识的深刻理解。
尝试使用了keras，确实好用，方便快捷，生成图像的函数ImageDataGenerator很好用。不过听说pytorch的速度比tensorflow要快啊，keras的底端默认是调用的tensorflow，下次编程实践试试pytorch。
有几次自己思考过后，改了改模型运行完提交之后，看到public LB得分下降了，就没有继续尝试了，然后赛后才看到那几次在private LB上的得分还升高了呢。所以啊，还是得相信自己的知识，不应该一味的看着public LB然后怀疑自己的知识。
1 高分答案集锦 第一名 David 画图理解图像很重要,把数据项inc_angle可视化出来很重要,他也发现了
inc_angle的重要性,不同类型的分类，很重要。
始终坚信自己的本地cv很重要。
他有个cnn pipeline，直接先100个模型训练一下看看，惊掉我下巴有没有
对inc_angle做聚类算法，识别分类，确认此参数非常有效，logloss对于极端值错误惩罚比较严重，设置一个阈值好了
重新针对另外的类别，训练100多个模型，这下训练效果非常好了，对比其他参赛者，有显著提升
附上作者原文:So in summary, 200+ CNN models, a handful of clustering algorithms, a few different thresholds, a heavy reliance on inc_angle, don’t push log_loss thresholds to the extreme, trust your local CV, and you have a formula for a winning solution.</description></item><item><title>deeplearning.ai之卷积神经网络课程总结</title><link>https://yyq.github.io/posts/2017/2017-11-13-cnn/</link><pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2017/2017-11-13-cnn/</guid><description>等了一个月，coursera上的deeplearning.ai的第四门课程终于放出来了，月初忙了几天没空，这两天有空，认认真真刷掉了这门课（看过每一个视频，理解到位每一段视频内容，选择题作业满分，编程作业以及附加作业全部pass）。
在知乎上看过了https://zhuanlan.zhihu.com/p/21930884，中文版的CS231n(by stanford Li FeiFei)的全部notes，受益匪浅，再补一波吴恩达老师的此课，颇有收获。
知识点总结如下：
第一周 卷积神经网络 Understand the convolution operation Understand the pooling operation Remember the vocabulary used in convolutional neural network (padding, stride, filter, ...) Build a convolutional neural network for image multi-class classification 简介计算机视觉 通过简单的矩阵来卷积，进行边缘检测，本科时的数字图像处理课程学过，这个简单 padding, 为了卷积时不把边角的像素忽略掉，得按照卷积核的大小在图像周围一圈补充像素，常用的有两种， valid padding也就是no padding，input: n*n with filter f*f, output: (b-f+1)*(n-f+1) same padding,也就是输出矩阵和输入矩阵一样大，这样来计算的话n+2p-f+1=n,所以p=(f-1)/2,啊哈，所以啊，最好一般你的filter都用奇数，搞了偶数那same padding就不好做了哈 stride,步长，按照字面意思就好理解了，为了卷积的同时做采样 input: n*n with filder f*f padding=p ouput is : round((n+2p-f)/s+1), round为向下取整 三维矩阵的卷积，当时彩色图像的时候，比如一个图像是6*6*3，6乘以6的矩阵是图像大小，3是channel的数量，那么filter不能再是3乘以3了，得用3*3*3了，前面两个3是filer的高度和宽度，第三维的3也是channel数，必须和图像的channel一样匹配好才是.</description></item></channel></rss>