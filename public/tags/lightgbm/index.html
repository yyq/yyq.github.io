<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>LightGBM | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content>
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<link href=/tags/lightgbm/index.xml rel=alternate type=application/rss+xml title="Young Story">
<link href=/tags/lightgbm/index.xml rel=feed type=application/rss+xml title="Young Story">
<meta property="og:title" content="LightGBM">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://yyq.github.io/tags/lightgbm/">
<meta itemprop=name content="LightGBM">
<meta itemprop=description content><meta name=twitter:card content="summary">
<meta name=twitter:title content="LightGBM">
<meta name=twitter:description content>
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class="pb3-m pb6-l bg-black">
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
<div class="tc-l pv3 ph3 ph4-ns">
<h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
LightGBM
</h1>
</div>
</div>
</header>
<main class=pb7 role=main>
<article class="cf pa3 pa4-m pa4-l">
<div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links nested-img mid-gray">
<p>Below you will find pages that utilize the taxonomy term “LightGBM”</p>
</div>
</article>
<div class="mw8 center">
<section class="flex-ns flex-wrap justify-around mt5">
<div class="relative w-100 mb4 bg-white">
<div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2018/2018-06-29-kaggle-avito/ class="link black dim">
kaggle | avito-demand-prediction top 10%
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
题目链接:kaggle, avito是一家俄罗斯公司，从网站上来看是一个线上购物平台，这一次题目的目标，就是预测某一个商品在某一天被售出的概率，给定的数据有一段时间内的商品的销售情况（数量，价格，地区，品类，商品的全面俄文描述，商品的图片）等信息。
我的kaggle账号：https://www.kaggle.com/yyqing/competitions
丢了top10% 自己的时间规划出了点问题，工作上临时加了点任务，所以玩比赛这边就少花了点时间，水平也不到位，本来在勉强拿到10%的最后一名，当剔除违规竞赛者之后，排在了10%之外。:(
很少有题目同时用到了GBDT,CV,NLP的，这次算是遇到一个，算是涨了见识，有人取胜重点靠抽取到商品图像的特征，有人取胜重点靠全量商品描述的词向量，有人取胜在于强大的ensemble各路模型各路特征。这一次我入场比较晚，找人组队就很难了，一个人打还是比较累的，虽然利用到了之前储存好的各种代码片段，不过还是时间太紧，精力有限，再加上我是球迷，我德表现如此糟糕，于是，哎哟喂，我也表现如此糟糕
自己的收获 短短10天，虽然成绩不佳，但是知识和技能上的收获还是感觉满满的：
组合模型在这一题发挥了重要的作用，我除了自己训练了xgb，lgb和catboost之外，还从讨论区拷贝来了rnn，ridge regression的成果 自己没怎么实践过自然语言处理，照猫画虎罗列好了tfidf，pca，svd等等，微调一下ngram，对自己分数提高还有有用的 认真按照自己的思路对着各路category实践了target encode，感觉用处不大，过拟合有点重了，后来在讨论中得知，大神们用的高阶的target encode还有加噪音加平滑，据说也有用，下次我也玩高级的TE 由于是第一次搞词向量的题目，第一次实践了稀疏矩阵，lgb和xgb都支持，catboost还不支持，不过用pca将稀疏矩阵做成少量几列还是可以喂给catboost用 拼接各种数据的时候，numpy的运算速度比dataframe要快，有的时候直接用pandas做数学运算，慢到出奇，不如把数据先导出到numpy，运算完再重填回dataframe，节约时间大于一个数量级 压缩数据在内存中占的体积，link这个参考很不错 多线程提取图像特征，参考这里，让我差不多一天时间就把大约180万张图的基本特征都拿出来了。 在处理大量小图片的时候，固态硬盘比机械硬盘的优势就显示出来了，机械硬盘的IOPS实在是跟不上cpu gpu的推理速度，分分钟就到瓶颈，不过GCP上的几百GB ssd价格好贵啊，玩了一会儿做完图像就赶紧换回了机械硬盘。 高分答案集锦 这一次由于数据的丰富性，值得学习的思路很多，且很多大神分享的思路会有部分重合，这里只摘抄我认为最值得学习并且去重的部分思路
1st, Little Boat, Dance with Ensemble 有一些lgb，有一些nn，有一些xgb作为第一层，第二层还是一些lgb+nn+xgb,第三层就是一个nn了。不过这么组合出来分数提升了大约0.0002到0.0004，和直接线性组合比起来，可能差不多。
最佳单模型的nn和lgb都做到了215x的分数，另外队友加来一个大量商品描述+RNN做出来的特征，给lgb分数boost到了213x。
stacking在这一局非常重要，模型的多样化是取胜的关键，
神经网络 我自己是重点时间都放NN了，所以也没怎么做特征工程。我就来分享一下如何用一个nn做到215x的吧。
数字特征加上类别特征，分数有0.227x 加上了title和description都用rnn训练一下，再加上fastText预训练的embedding，调整一下，分数到了0.221x 自训练的fastText embedding，在全量数据上，分数到了0.220x 加上vgg16的top layer的平均池化，这个让分数变差了。tuning一下，在合并文本、图像、类别、数字特征之前，分别加了一层，有了效果，0.219x了 尝试调整文本模型，CNN或者attention等等，没有一个work。最后，两层的LSTM加一个dense，提高了分数0.0003 给图像尝试不同的CNN，没有一个“fine tune”的模型有用，并且还花了很多时间。最后发现fixed ResNet50的中间层有用，提高了0.0005， 到了0.218x了 开始各种tuning，都是基于自己想法的去调，发现在text和LSTM之间加上spatial dropout超级有用，提升了大约0.0007到0.001，又结合调整了dropout的比例，提升了0.001到0.0015，分数到了0.2165到0.217 开始把队友做的特征都加进来，队友做的文字类的特征加进来都没啥用，不过其他类的特征都有用，最后一个NN做到0.215x 如果一路上把所有模型都存下来（少量特征训练的模型，加了特征分数变差的模型），然后再训练一个全连接on top of those,可以得到0.008的提升，这个分数可以进入前10名了 秀一下我的模型架构图吧： 评论区摘抄 我在评论中看到他有说，keras的RNN模型，用CuDNN实现的来运行的话，会快很多。
然后他贴出了他的rnn代码：
seq_title_description = Input(shape=[max_seq_description_length], name="seq_description") emb_seq_title_description = Embedding(vocab_size, EMBEDDING_DIM1, weights=[embedding_matrix1], trainable=False)( seq_title_description) emb_seq_title_description = SpatialDropout1D(0.
</div>
</div>
</div>
</div>
<div class="relative w-100 mb4 bg-white">
<div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2018/2018-05-09-talking-data/ class="link black dim">
kaggle | talkingdata-adtracking-fraud-detection top 4%
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
题目链接:kaggle, talkingdata是一家中国公司，我将其理解成一个第三方的移动数据平台，移动端的广告分发是其一个重要业务，其中会出现一些恶意的点击，这个比赛的意义在于：他们想要通过机器学习的方式抓出其中的欺诈类型的点击。
我的kaggle账号：https://www.kaggle.com/yyqing/competitions
纪念一下自己的第一个solo 银牌 之前有个比赛进过前5%的，不过由于用了两个账号在轮番提交，被取消成绩了。这次算是记住教训了，就一个账号玩，依然solo，排名122/3967，public LB score 0.9898130, private LB 0.9821300, mark一下，离自己的mater目标迈出了重要的一步。另外值得庆幸的是，这是第若干次比赛成绩出来后，我的私榜排名是比公榜排名进步的，证明我的模型的泛化能力一直还行，至少是领先于kaggle上大家的平均水平的。
这次比赛的最后一次ensemble结果提交是在回湖南的火车上完成的，正好看到kaggle社区总积分的新晋No.1&ndash;bestfitting的访谈博客，这位同学竟然是长沙人，也是蛮意外的。我努力向老乡学习吧。
自评：又一场内存的战役 学到了很多，这些知识大概不会有哪本书籍有写，也不会有哪个视频教程说，都是自己摸爬滚打得来的，主要是对于大量数据的存，取，和运算。公司也没有给我集群机器玩的情况下，只能自己在谷歌云上玩了。当自费的玩大容量云主机的时候，全都按时收费，每一个GB内存和硬盘都要收费，每一个cpu core都收费的情况下，我会格外的在意，我会最大化的利用cpu，内存等"昂贵"资源。穷嘛，省时间就是省钱。
接下来就说一些在有关方面的技巧吧
习惯性的del不再使用的数据，then gc.collect() could save your asshole. 很多时候调整模型都要考虑使用或者更改不同的特征，当你有几十个特征，每个特征的存放都会占用GB级别的资源的时候，不要尝试一次性处理所有的特征。一个一个来，180Million的数据，一个特征，一次开一个进程，只计算一个特征，比如groupby过程中会爆炸到20多GB的内存，虽然最后计算完结果只有1GB内存。 不要尝试将包含所有特征的大表存成一个文件，将每一个特征保存成一个单独文件。之后要用到这个特征的时候，再读取进来join到dataframe中。提高灵活性，用哪些我就只载入哪些。 pandas读取大体积（1GB或者更大）csv文件速度很慢，特别是当我有几十个特征，每个特征都有一两GB的时候，pandas读取一个30GB的csv文件所花费的时间，绝对会让你崩溃。这个时候pandas.read_feather()和pandas.to_feather()是一个很好的方式，直接把一个dataframe的内容，以feather的格式，从内存dump到磁盘，不用管csv的index等等相关参数，就是dump什么样的内容到磁盘，读取回来还是什么内容在内存，重点是，速度比read_csv快了一个数量级。 关于pandas有点慢的问题，期间还认真尝试过dask和pandas on ray两个开源工具，dask功能齐全一些，在有一些操作比pandas快很多，不过在这次实践中对我的时间节约没有太多的帮助，所以没用。pandas on ray的话，显然还不太成熟，各种常用函数缺失，遂放弃。 每一次探索新特征的时候，一定要有一个较小的可用的可靠的快速的validation的方案，来验证新的特征是否有效。不然每次都用全量的数据来计算，时间成本太高。 每一次运行时间较长的实验（比如全量数据，比如超小的学习率）之前，一定得有一个debug pipeline，快速走完整个过程。 养成随时save model的好习惯。之前做图像深度学习的时候还知道存下很多个epoch完毕之后的模型文件，没成想lightGBM在遇到稍微大点的数据集的也会有各种坑。比如有时候会遇到训练到一半，内存炸了，程序崩了，比如有时候会train完毕后没有及时清理删除训练数据集，predict的时候内存炸了。想起mxnet的李沐博士的视频里说的，我就是不小心把整栋机房弄停电了嘛，你们跑了三四天的程序都不保存中间模型，那能怪我喽，谁叫你们不随时保存的。 哎呀，说多了都是泪，对于我个人来说都是浪费的钱啊，以后想起来什么泪点，我再补充到这个段落来。 高分答案集锦 接下来欣赏欣赏别人的思路吧
3rd, bestfitting, NN based solution 在同时做另外一个google landmark的题目，正好发现最近的NN模型可以用，就在这里也直接用NN了。（大神就是可以模型广泛应用到各个业务上，难道以后深度模型要统治所有，彻底打败树么）。他的主要尝试了的是23个特征，用single LGBM做到了在public LB分数0.9817。（这分数比我最终提交的分数还高），这是他第一次在kaggle里用LGBM。
设计了基于那23个特征，并且适当处理后(NA, out of vocabulary, scale)，用NN做到了公榜0.9820，然后论坛上发现click delta是个重要线索，于是多做了前五个和后五个click的时间序列加到网络里，用RNN来寻找点击序列的模式，模型可以做到公榜9821了。然后设计了不同的神经网络来增加多样性，都是很简单的，比如增加一些残差链接到dense层。四个模型，不单独考虑分数，只考虑综合起来的多样性带来的提升。在组装了神经网络和lgbm模型的成绩之后，分数到了9827。
再加上n-fold和全部数据。稍微有点花时间了，一个fold就两个多小时，一块1080i的GPU.
然后用之前的模型在整个数据集上预测的结果，再加上一些特征（基于IP的，app-os-channel），做了第二层神经网络,分数到了9833。最后的这个提升做好的时候，离比赛时间结束只有30个小时了，来不及其他改进了，时间限制，NN模型的弱点，等等，就酱。他用到的一些特征如下：
channel 1011 os 544 hour 472 app 468 ip_app_os_device_day_click_time_next_1 320 app_channel_os_mean_is_attributed 189 ip_app_mean_is_attributed 124 ip_app_os_device_day_click_time_next_2 120 ip_os_device_count_click_id 113 ip_var_hour 94 ip_day_hour_count_click_id 91 ip_mean_is_attributed 74 ip_count_click_id 73 ip_app_os_device_day_click_time_lag1 67 app_mean_is_attributed 67 ip_nunique_os_device 65 ip_nunique_app 63 ip_nunique_os 51 ip_nunique_app_channel 49 ip_os_device_mean_is_attributed 46 device 41 app_channel_os_count_click_id 37 ip_hour_mean_is_attributed 21 (可以看出来几类特征比较有效，click_time_next，target mean code，count，unique count，还有就是大多特征都是基于ip和其他特征组合来的)
</div>
</div>
</div>
</div>
</section>
</div>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>