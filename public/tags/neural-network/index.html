<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>Neural Network | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content>
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<link href=/tags/neural-network/index.xml rel=alternate type=application/rss+xml title="Young Story">
<link href=/tags/neural-network/index.xml rel=feed type=application/rss+xml title="Young Story">
<meta property="og:title" content="Neural Network">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://yyq.github.io/tags/neural-network/">
<meta itemprop=name content="Neural Network">
<meta itemprop=description content><meta name=twitter:card content="summary">
<meta name=twitter:title content="Neural Network">
<meta name=twitter:description content>
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class="pb3-m pb6-l bg-black">
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
<div class="tc-l pv3 ph3 ph4-ns">
<h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
Neural Network
</h1>
</div>
</div>
</header>
<main class=pb7 role=main>
<article class="cf pa3 pa4-m pa4-l">
<div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links nested-img mid-gray">
<p>Below you will find pages that utilize the taxonomy term “Neural Network”</p>
</div>
</article>
<div class="mw8 center">
<section class="flex-ns flex-wrap justify-around mt5">
<div class="relative w-100 mb4 bg-white">
<div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2017/2017-08-05-machine-learning-week5/ class="link black dim">
coursera Andrew Ng 机器学习第五周笔记 神经网络的学习过程
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
Neural Networks: Learning cost function L = total number of layers in the network sl = number of units (not counting bias unit) in layer l K = number of output units/classes the double sum simply adds up the logistic regression costs calculated for each cell in the output layer the triple sum simply adds up the squares of all the individual Θs in the entire network. the i in the triple sum does not refer to training example i Backpropagation Algorithm Backpropagation in Practice thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ] deltaVector = [ D1(:); D2(:); D3(:) ] Theta1 = reshape(thetaVector(1:110),10,11) Theta2 = reshape(thetaVector(111:220),10,11) Theta3 = reshape(thetaVector(221:231),1,11) gradient checking Once you have verified once that your backpropagation algorithm is correct, you don&rsquo;t need to compute gradApprox again.
</div>
</div>
</div>
</div>
</section>
</div>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>