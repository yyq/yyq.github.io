<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>neural networks | Young Story</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content>
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<link href=/tags/neural-networks/index.xml rel=alternate type=application/rss+xml title="Young Story">
<link href=/tags/neural-networks/index.xml rel=feed type=application/rss+xml title="Young Story">
<meta property="og:title" content="neural networks">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://yyq.github.io/tags/neural-networks/">
<meta itemprop=name content="neural networks">
<meta itemprop=description content><meta name=twitter:card content="summary">
<meta name=twitter:title content="neural networks">
<meta name=twitter:description content>
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class="pb3-m pb6-l bg-black">
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
Young Story
</a>
<div class="flex-l items-center">
<div class=ananke-socials>
</div>
</div>
</div>
</nav>
<div class="tc-l pv3 ph3 ph4-ns">
<h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
neural networks
</h1>
</div>
</div>
</header>
<main class=pb7 role=main>
<article class="cf pa3 pa4-m pa4-l">
<div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links nested-img mid-gray">
<p>Below you will find pages that utilize the taxonomy term “neural networks”</p>
</div>
</article>
<div class="mw8 center">
<section class="flex-ns flex-wrap justify-around mt5">
<div class="relative w-100 mb4 bg-white">
<div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2018/2018-02-24-sp-society-camera-model-identification/ class="link black dim">
kaggle | sp-society-camera-model-identification 看图认相机
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
此题目标为根据照片来判断牌照相机的型号
这件事情的原理是：每一家设备都有自己的数字图像处理算法，总会有属于自己的图像特征
这件事情的意义在于：警察破案，图片是否有被软件修改等等
我的kaggle账号:https://www.kaggle.com/yyqing/competitions
0 自评 自己做的第二个图像类的题目，最大的收获就是体验到了extra data的威力，在论坛区看到有大家讨论说使用额外的一些的数据，50GB的训练集果然效果不错，直接把我的public LB成绩从0.87提升到0.92，后来经过自己的各种transfer learn和fine tune keras里的一些模型，然后组合，在private LB拿到了0.96的分数。看看排名前几的大神的总结里，很多人都使用了比我找的数据集更大的数据集，所以准确率也比我高出几个数量级（第一名0.9896）。
训练大量图像是一件非常非常消耗时间的事情，优化的方向有这么几个：1)切取大图像中的小块来训练;2)显卡计算能力利用率提高，注意显卡的频率，内存，注意程序中的CPU处理部分，做到及时处理一直给显卡喂数据，别让显卡时忙时闲 3)算法的优化，能并行做计算的部分尽量，不过注意估算好显卡的内存消耗，过大过小都是一种浪费 4)transfer来的不同的模型，参数数量不一样，最小图片像素也不一样 5) 做好pipeline
1 高分答案集锦 第一名 Pavel Pleskov 模型 参考了Andres的代码，用pyTorch实现了，如下模型有较好的效果
984_densenet201_antorsaegen_29_0.98624 976_densenet201_antorsaegen_62_0.98271 977_resnet50_antorsaegen_119_val_0.9815 976_DenseNet201_do0.3_doc0.0_avg-epoch072-val_acc0.981250 967_InceptionResNetV2_do0.1_avg-epoch154-val_acc0.965625 962_Xception_do0.3_avg-epoch079-val_acc0.991667 (leaky validation, pls ignore) 所有模型的输入图像都用的512*512，并且都是Test Time Augmentation(测试时也用增强过的数据)。这里是最大败笔，因为后来发现及时用较小size的图片可以更快的训练，然后更多的TTA可以达到相似的准确率
数据 我服，他另外下载了300GB从flickr和yandex.foto的图片。过滤掉分别率不适合的图片，质量不好的图片（图片质量可以用ImageMagick得到），自己用selenium做爬虫抓来的图片。
硬件 五个队员，有五个1080ti和一个1070
提交 平均所有的TTA所有的模型，by power mean powers of 1 2 4.最后有较大的LB overfit, public LB 0.991 private LB 0.985 通过hold-out，融合预测结果。20个xgboost，20个lightGBM，12个Keras，public LB 0.986, private LB 0.989. 关键点 收集尽可能多的图像数据，做好清理 尝试更小的图片切图，尝试所有的架构类型 LB probing是恶魔，相信自己的CV.
</div>
</div>
</div>
</div>
<div class="relative w-100 mb4 bg-white">
<div class="relative w-100 mb4 bg-white nested-copy-line-height">
<div class="bg-white mb3 pa4 gray overflow-hidden">
<span class="f6 db">Posts</span>
<h1 class="f3 near-black">
<a href=/posts/2018/2018-01-25-statoil-iceberg-classifier-challenge/ class="link black dim">
kaggle | statoil-iceberg-classifier-challenge 捡到铜牌一个
</a>
</h1>
<div class="nested-links f5 lh-copy nested-copy-line-height">
此题目标为识别图像中是否有冰山，数据图像均为卫星拍摄海面获得
我的kaggle账号:https://www.kaggle.com/yyqing/competitions
0 自评 第一次开始尝试图像的题目，和普通回归类的题目还真是不一样，除了修改一些别人的模型看得懂别人模型之外，自己还没有水平直接改进到10%。coursera的课程知识不够用了，觉得自己有知识瓶颈了，计划把cs231n刷一遍（中文字幕的，编程作业一定自己完成的），目标要至少做到：在不做实验的情况下，增删改查模型的各个地方，对自己的运行结果，得利用先验理论知识进行预判。这样的话，可以在实践各种方案的同时，持续强化自己对理论知识的深刻理解。
尝试使用了keras，确实好用，方便快捷，生成图像的函数ImageDataGenerator很好用。不过听说pytorch的速度比tensorflow要快啊，keras的底端默认是调用的tensorflow，下次编程实践试试pytorch。
有几次自己思考过后，改了改模型运行完提交之后，看到public LB得分下降了，就没有继续尝试了，然后赛后才看到那几次在private LB上的得分还升高了呢。所以啊，还是得相信自己的知识，不应该一味的看着public LB然后怀疑自己的知识。
1 高分答案集锦 第一名 David 画图理解图像很重要,把数据项inc_angle可视化出来很重要,他也发现了
inc_angle的重要性,不同类型的分类，很重要。
始终坚信自己的本地cv很重要。
他有个cnn pipeline，直接先100个模型训练一下看看，惊掉我下巴有没有
对inc_angle做聚类算法，识别分类，确认此参数非常有效，logloss对于极端值错误惩罚比较严重，设置一个阈值好了
重新针对另外的类别，训练100多个模型，这下训练效果非常好了，对比其他参赛者，有显著提升
附上作者原文:So in summary, 200+ CNN models, a handful of clustering algorithms, a few different thresholds, a heavy reliance on inc_angle, don’t push log_loss thresholds to the extreme, trust your local CV, and you have a formula for a winning solution.
</div>
</div>
</div>
</div>
</section>
</div>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://yyq.github.io/>
&copy; Young Story 2022
</a>
<div>
<div class=ananke-socials>
</div></div>
</div>
</footer>
</body>
</html>