<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>image on Young Story</title><link>https://yyq.github.io/tags/image/</link><description>Recent content in image on Young Story</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 30 Mar 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://yyq.github.io/tags/image/index.xml" rel="self" type="application/rss+xml"/><item><title>记近两天调优图像训练的过程</title><link>https://yyq.github.io/posts/2018/2018-03-30-opt-image-training/</link><pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2018/2018-03-30-opt-image-training/</guid><description>起因 拿来小伙伴的代码，数据预处理阶段程序就跪了，找了找原因，内存用完了。要来他的top命令截图一看，呵呵，0.2t，小伙伴用的学校实验室的最好的机器，256GB的内存，玩起来当然没所谓，我用的公司的机器就略微寒酸了，内存32GB。我这个要玩的话，只能分批次读入图片，处理。 what i&amp;rsquo;ve done 认真找了找tensorflow的分批次读取数据的方案，有方法，找到了tf dataset的文档，功能强大，完全，可以一批一批高效的读进来数据给显卡时刻准备着。 后来还是放弃了tf的路子，现有的代码全是keras，把tf的代码嵌入进来，略微费劲儿了一点，况且我这次实验目标只是一个短期小实验，如果之后需要上线产品用再改用tf dataset或者TFRecord好了，在大量数据情况下配合集群hdfs会有更好的成效。 将来用的时候可以参考的这几个链接，描述tf读取数据的技巧： tensorflow 官网链接1 tensorflow 官网链接2 博客 a 博客 b 找到了keras里有也有分批次读取数据的玩法，叫做fit_generator, 找到了官网文档，然后也找到了一位斯坦福同学的博客，我就按着这两个做下来，恩，完成了，效果不错。 &amp;quot;&amp;quot;&amp;quot;stream data by batch&amp;quot;&amp;quot;&amp;quot; import numpy as np import keras from keras.utils import np_utils from PIL import Image class DataGenerator(keras.utils.Sequence): def __init__(self, data, batch_size=128, dim=(32, 128, 3), n_classes=21000, shuffle=True): &amp;quot;&amp;quot;&amp;quot; :param data: 包括了图片名称，路径，四个标签 :param batch_size: 一批训练128张图片 :param dim: 图片的维度 :param n_classes: 有多少种汉字 :param shuffle: 每个epoch末尾，是否打乱index顺序 &amp;quot;&amp;quot;&amp;quot; self.</description></item><item><title>deeplearning.ai之卷积神经网络课程总结</title><link>https://yyq.github.io/posts/2017/2017-11-13-cnn/</link><pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate><guid>https://yyq.github.io/posts/2017/2017-11-13-cnn/</guid><description>等了一个月，coursera上的deeplearning.ai的第四门课程终于放出来了，月初忙了几天没空，这两天有空，认认真真刷掉了这门课（看过每一个视频，理解到位每一段视频内容，选择题作业满分，编程作业以及附加作业全部pass）。
在知乎上看过了https://zhuanlan.zhihu.com/p/21930884，中文版的CS231n(by stanford Li FeiFei)的全部notes，受益匪浅，再补一波吴恩达老师的此课，颇有收获。
知识点总结如下：
第一周 卷积神经网络 Understand the convolution operation Understand the pooling operation Remember the vocabulary used in convolutional neural network (padding, stride, filter, ...) Build a convolutional neural network for image multi-class classification 简介计算机视觉 通过简单的矩阵来卷积，进行边缘检测，本科时的数字图像处理课程学过，这个简单 padding, 为了卷积时不把边角的像素忽略掉，得按照卷积核的大小在图像周围一圈补充像素，常用的有两种， valid padding也就是no padding，input: n*n with filter f*f, output: (b-f+1)*(n-f+1) same padding,也就是输出矩阵和输入矩阵一样大，这样来计算的话n+2p-f+1=n,所以p=(f-1)/2,啊哈，所以啊，最好一般你的filter都用奇数，搞了偶数那same padding就不好做了哈 stride,步长，按照字面意思就好理解了，为了卷积的同时做采样 input: n*n with filder f*f padding=p ouput is : round((n+2p-f)/s+1), round为向下取整 三维矩阵的卷积，当时彩色图像的时候，比如一个图像是6*6*3，6乘以6的矩阵是图像大小，3是channel的数量，那么filter不能再是3乘以3了，得用3*3*3了，前面两个3是filer的高度和宽度，第三维的3也是channel数，必须和图像的channel一样匹配好才是.</description></item></channel></rss>